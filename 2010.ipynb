{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2010.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"fRLkN0uEbeT5","colab_type":"text"},"cell_type":"markdown","source":["# Data Science for Medicine and Public Health: Applied Statistical Learning\n","**National Preventive Medicine Residency Program**<br>\n","**Resident-Led Session, 29 Mar 2018**<br>\n","\n","## Sample Code: Lung Cancer Diagnosis"]},{"metadata":{"id":"J7SptSwCbeT8","colab_type":"text"},"cell_type":"markdown","source":["You are given a dataset of 1105 chest X-ray (CXR) images, each described by 102 attributes and a label, where 1 indicates malignant lung cancer, and 0 indicates benign tumour. Your task is to build a classification model to predict whether a given CXR shows a malignant or benign tumour."]},{"metadata":{"id":"PXYyuwN1beT9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import scipy as sp\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import roc_curve, auc\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8g13fxdVbeUE","colab_type":"text"},"cell_type":"markdown","source":["## Data Preparation"]},{"metadata":{"id":"n20YMPQ8beUF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":904},"outputId":"0310d9b4-e127-4ce3-81e5-bf720308de33","executionInfo":{"status":"error","timestamp":1524234134356,"user_tz":180,"elapsed":713,"user":{"displayName":"Caio Peixoto","photoUrl":"//lh4.googleusercontent.com/-9GUiVqUIS0E/AAAAAAAAAAI/AAAAAAAAGIY/ixGuwHhyTXY/s50-c-k-no/photo.jpg","userId":"111983042396399795117"}}},"cell_type":"code","source":["# load and inspect the data\n","data_original = pd.read_csv('lungsample.csv')\n","\n","#df_dict = pd.read_excel('2010.xlsx',sheet_name=None)\n","#data = pd.concat(df_dict.values(), axis=0)\n","\n","data = pd.read_csv('2010.xlsx - None.csv')\n","data.head()\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-afd3f8fd89c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lungsample.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_dict = pd.read_excel('2010.xlsx',sheet_name=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#data = pd.concat(df_dict.values(), axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: File b'lungsample.csv' does not exist"]}]},{"metadata":{"id":"6l6C9MSkbeUP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"786b61f8-69ee-48bc-9d2f-deed4f44f648"},"cell_type":"code","source":["print(data_original)\n","data_original.shape, data.shape"],"execution_count":0,"outputs":[{"output_type":"stream","text":["            v0        v1        v2        v3        v4        v5        v6  \\\n","0    -0.164889  0.401110  0.555741  0.083018  1.248687  0.419196 -0.132630   \n","1     0.466852 -0.362214  0.290673  0.358680  0.288683  0.169915 -0.130182   \n","2    -0.385892 -1.351414  1.010566 -1.212319 -1.914623 -1.130040 -0.014538   \n","3    -0.188841  0.987212 -0.480216  0.162236  0.687001 -0.090172 -0.113926   \n","4     0.805155 -1.343913  0.068894 -1.066623 -1.697915 -1.105640 -0.004081   \n","5    -0.902733 -2.883427  0.271698 -1.306577 -1.756070 -1.099451  0.514924   \n","6    -0.916640 -1.179506 -0.126200 -0.779572  1.140494 -0.976118 -0.114371   \n","7    -0.088993  0.448359 -0.556119 -0.694098 -0.785462 -0.731451 -0.059460   \n","8     0.777437 -0.377060  0.356495 -0.716436 -1.570038 -1.096894  0.017807   \n","9     1.307274  0.211126 -0.183720 -0.943134 -0.340002 -0.974623 -0.039493   \n","10   -0.263579 -0.278448  0.223072 -0.118365  0.070949  0.105817 -0.108845   \n","11    0.442816 -0.274905  0.007223  1.031794 -0.591029 -0.976753  0.011987   \n","12    0.344443  0.431012  0.005444 -0.848263  0.453921 -0.529529 -0.109524   \n","13    0.930953  0.510089  0.390296  0.499030  0.019268 -0.373552 -0.112116   \n","14   -0.614631 -0.218280  0.545660  0.576587  0.110902  0.241248 -0.139989   \n","15   -0.576441  0.549889 -0.429219  0.729284  0.402325  0.087606 -0.124942   \n","16    0.519672 -0.271780  0.103288 -1.469604 -1.206006 -0.995052  0.065443   \n","17    0.059383  0.854270  0.140646 -0.415010 -0.236830 -0.298403 -0.098887   \n","18    0.713305  0.162210 -0.098922 -1.994250  0.101450 -0.916568 -0.062817   \n","19    0.096959  0.244830 -0.688949  0.430000  0.660950  0.628262 -0.145780   \n","20   -0.190350  1.141617 -0.444044  0.262612  0.262928  0.064479 -0.122265   \n","21    0.872082  0.891725  0.488140  0.235320  0.013041 -0.074509 -0.112042   \n","22   -0.851710 -0.299754 -0.012939  0.294396 -0.019108 -0.079693 -0.139949   \n","23    1.288148  0.799416 -0.576874 -0.543138 -0.688197 -0.548698 -0.135382   \n","24   -0.272572  0.389076  0.231374 -1.366407 -0.909651 -0.971896 -0.064895   \n","25    0.026721 -0.272561  0.114555  0.265978  0.207957  0.418251 -0.157757   \n","26   -1.057545 -1.706222 -0.049111 -0.570866 -1.127158 -0.873762 -0.016946   \n","27   -0.298179  0.901310  0.690350  0.279713  0.258157 -0.113207 -0.113526   \n","28   -0.337364 -0.295430  0.518382  0.001584 -0.044636 -0.075904 -0.115728   \n","29   -0.918755  0.354486 -0.024205  0.519720 -0.079847 -0.124321 -0.117268   \n","...        ...       ...       ...       ...       ...       ...       ...   \n","1074 -0.319207  0.299632  0.575310  0.155345  0.112411 -0.241520 -0.125683   \n","1075 -0.126632  1.074729  0.524312 -0.116410  0.551531  0.331356 -0.126931   \n","1076  0.807825  0.718879  0.840377 -1.441120 -1.024712 -0.861168 -0.025214   \n","1077  0.024716  1.036701  0.384959 -0.550507  0.403810 -0.020979 -0.108708   \n","1078 -0.746426  0.306613  0.807169  0.015839  1.393022 -0.200699 -0.130845   \n","1079 -0.560925 -0.011782  0.511266  0.295743  0.172855 -0.244941 -0.120019   \n","1080 -0.329119  0.233109  0.354123  0.186465  0.599208  0.095944 -0.128082   \n","1081  0.057410  0.977054  0.501779 -0.429593 -0.225950 -0.432474 -0.078565   \n","1082  0.180835  1.047901  0.606738 -1.030380 -0.606764 -0.662794 -0.066712   \n","1083 -0.331535  0.299788  0.010188  0.313327  0.720018  0.458339 -0.133864   \n","1084 -1.443774 -2.084940  0.542695  0.019460 -1.636177 -1.124267  0.211835   \n","1085 -1.357653 -2.290501  0.569973 -0.038387 -1.704190 -1.102658  0.228490   \n","1086  0.301932  0.073026  0.278814 -0.648267  0.272639 -0.437052 -0.116262   \n","1087  1.592627 -1.066776  0.207654 -1.934832 -1.849360 -1.122069  0.115244   \n","1088  0.124635 -4.692629  0.776927 -0.336859 -2.121897 -1.137839  1.011875   \n","1089  2.841362  0.407361  0.994555 -1.091312 -1.726964 -1.090874  0.192382   \n","1090 -0.103862  0.619173  1.059191 -1.222014 -0.790813 -0.807196 -0.059010   \n","1091 -1.149863 -0.568034 -0.326038 -0.766037 -1.114359 -0.888916  0.095720   \n","1092 -0.567314 -0.400763 -0.303505 -0.540966 -0.588153 -0.841785 -0.012563   \n","1093  0.751604  1.002215  0.377843 -0.932737 -0.438869 -0.686147 -0.066511   \n","1094 -0.623732  1.113330  0.488733 -0.417226 -0.487464 -0.472350 -0.064228   \n","1095 -0.413155  0.530145  1.021240  0.300226  0.767919  0.292853 -0.131205   \n","1096 -0.535831  0.497899  1.015310 -0.021847 -0.097380 -0.325524 -0.129815   \n","1097  0.905379  0.711274  1.151698 -2.314672 -1.151352 -1.020927 -0.048427   \n","1098  1.004817  0.622871  1.110781 -2.408095 -1.191046 -1.033501 -0.052338   \n","1099 -0.123778  0.979971  1.039029 -1.941054 -1.173910 -0.980800 -0.015088   \n","1100 -0.111220  0.909124  1.055040 -2.054937 -1.276725 -0.995443  0.019395   \n","1101  0.221202  0.673141  0.367762 -1.087115 -0.540135 -0.629128 -0.067752   \n","1102 -0.341246  1.039462 -0.396011  0.269866  0.367312  0.018028 -0.148229   \n","1103 -1.456431 -2.618897 -0.022426  0.293618 -1.628295 -1.087773  0.434779   \n","\n","            v7        v8        v9  ...         v93       v94       v95  \\\n","0    -1.011638  1.189815 -0.558548  ...    0.990005 -0.234665  0.486476   \n","1     0.823796  0.271589  1.069925  ...    0.685890  0.035272  0.249075   \n","2    -0.587020 -1.906679  1.019006  ...   -1.878473  0.494254  0.856842   \n","3    -0.618971  0.607489 -0.471608  ...    0.734663 -0.070419 -0.408618   \n","4    -0.339155 -1.696933  0.712826  ...   -0.710760  0.134040  0.069241   \n","5    -0.767923 -1.749447 -0.930261  ...   -0.350583  0.385349  0.233282   \n","6     0.809596  0.753175  1.433263  ...   -2.717596  0.415497 -0.167141   \n","7    -0.067645 -0.790496 -0.127948  ...    0.690648  0.045689 -0.477393   \n","8    -0.630306 -1.574130  1.456696  ...   -1.738021  0.212354  0.305623   \n","9    -0.591821 -0.396751  0.391770  ...   -0.416697  0.055068 -0.126386   \n","10    0.234647  0.056404  0.687389  ...    0.759442 -0.300297  0.203225   \n","11   -0.401728 -0.635844 -0.135045  ...   -0.457679  1.873352 -0.004629   \n","12   -0.722000  0.368964 -1.229032  ...   -0.111967 -0.169706 -0.002591   \n","13   -0.211348  0.011176  0.338070  ...    0.885989 -0.489443  0.354020   \n","14   -0.410617  0.150438 -0.376759  ...    0.378891 -0.290805  0.469664   \n","15    0.042023  0.370359 -0.298899  ...    1.170346 -0.269094 -0.370410   \n","16   -0.700562 -1.211101 -1.624708  ...    0.434415  0.149868  0.064146   \n","17    1.454783 -0.246545  0.875090  ...    1.242788 -0.110940  0.125789   \n","18   -0.208426  0.026631  1.298361  ...    0.387588  0.047090 -0.052516   \n","19   -0.615797  0.647337 -1.417539  ...    0.018925 -0.220663 -0.609849   \n","20    0.473504  0.258520  0.409617  ...    0.612071 -0.120573 -0.397920   \n","21    0.995728 -0.008024  1.057911  ...    0.245442  0.070953  0.422286   \n","22   -0.198469 -0.000384 -0.050698  ...    0.787563 -0.033043 -0.006157   \n","23   -0.669300 -0.687896 -0.629812  ...    0.347716 -0.010877 -0.479940   \n","24   -0.884602 -0.922579 -2.025519  ...    0.091383  0.057269  0.192017   \n","25   -0.208076  0.282215 -0.154613  ...   -0.109596 -0.235148  0.107449   \n","26   -0.863679 -1.130980 -1.384141  ...    0.259997 -0.155216 -0.047931   \n","27   -0.487161  0.226524 -1.794824  ...    0.759188 -0.141758  0.563912   \n","28   -0.304913 -0.063972  0.119505  ...    0.494648 -0.264436  0.446739   \n","29    0.666044 -0.059098  0.308405  ...    0.691140 -0.283230 -0.004629   \n","...        ...       ...       ...  ...         ...       ...       ...   \n","1074  1.172899  0.078745  0.912157  ...    1.230164 -0.061773  0.492589   \n","1075  0.616173  0.558373  0.740857  ...    0.564266 -0.278234  0.445720   \n","1076  3.341353 -1.029641  1.728583  ...    0.581833  0.026063  0.726424   \n","1077 -0.055170  0.352166  0.925384  ...    0.813100 -0.155601  0.339246   \n","1078 -0.547168  1.358426 -0.814768  ...    0.566891 -0.261192  0.694329   \n","1079  1.408825  0.181936  0.630638  ...   -0.053628 -0.078750  0.452343   \n","1080  1.025759  0.610458  0.935568  ...    0.640898 -0.308991  0.312755   \n","1081 -0.055404 -0.229789  0.030800  ...    0.688683  0.019080  0.429928   \n","1082  4.052357 -0.614417  2.001452  ...    0.903479  0.071928  0.539458   \n","1083 -0.244691  0.683632  0.298156  ...    0.730457 -0.300805  0.030014   \n","1084  0.891245 -1.641952  0.213781  ...   -0.737324  2.948939  0.437569   \n","1085  0.399051 -1.705683  0.174193  ...   -0.812526  1.912742  0.466098   \n","1086 -0.046205  0.229816  0.313330  ...    0.756044 -0.040369  0.235320   \n","1087 -0.918584 -1.842489 -0.315933  ...   -1.370042  0.067475  0.159922   \n","1088  0.151106 -2.106076  0.932902  ...   -2.442571  0.327566  0.666819   \n","1089  0.428237 -1.719360  1.446737  ...   -1.445111  0.031202  0.858370   \n","1090  0.749324 -0.801721  0.287253  ...    0.589627  0.179439  0.913390   \n","1091 -0.714556 -1.109023 -0.273818  ...    0.001427 -0.242875 -0.253747   \n","1092 -0.359379 -0.601621  0.394996  ...   -0.590654 -0.178628 -0.242030   \n","1093  1.542073 -0.462077  1.245198  ...    0.923565 -0.032057  0.334152   \n","1094  0.419353 -0.478128 -0.181191  ...    0.843528  0.055656  0.416682   \n","1095  0.302009  0.767725 -0.119202  ...   -0.336905 -0.130636  0.879767   \n","1096  0.060884 -0.126577 -0.125456  ...    0.741729  0.193304  0.869069   \n","1097  1.671655 -1.166378  2.221709  ...    0.223279  0.013927  0.988279   \n","1098  1.288204 -1.206920  2.229300  ...    0.261328  0.033066  0.960259   \n","1099  1.179001 -1.182735  1.954245  ...    0.192377  0.161363  0.901164   \n","1100  1.141813 -1.279400  2.165742  ...    0.086736  0.158723  0.925108   \n","1101  0.306593 -0.554887 -0.445161  ...    0.153705 -0.004580  0.290340   \n","1102 -0.673252  0.334765 -0.244857  ...    0.722017  0.077507 -0.332711   \n","1103  2.108259 -1.627206  1.568026  ...   -0.915785  1.241795 -0.004119   \n","\n","           v96       v97       v98       v99      v100      v101  label  \n","0     0.156383 -0.079373 -0.167362 -0.581883 -0.981381  0.772401      0  \n","1    -0.584769 -0.635233  0.389731 -0.506207 -0.706763 -0.805263      0  \n","2     2.750338  0.224587  0.470562  2.985488 -1.552287  1.107159      0  \n","3     1.122769 -1.219642 -0.058283 -0.431281  0.116943  1.555012      0  \n","4     0.961440  0.659535 -0.007964  0.522000 -0.065184  0.012408      0  \n","5    -0.057879  0.204435 -0.186306  0.578977 -0.458212  0.467046      0  \n","6    -2.523665 -2.914093 -3.096888  1.214547 -0.081719  1.367276      0  \n","7    -0.086841  0.201076 -0.794852 -0.066410  0.181658 -1.154723      0  \n","8     0.756221 -0.198606  0.316025  1.486271 -0.632695  0.299667      0  \n","9     1.380955 -1.009725  0.579610  0.150991  0.376081 -0.171935      0  \n","10   -0.504030 -0.247307 -0.614397 -0.626871 -0.457184 -1.135497      0  \n","11    0.740308  0.978609  0.266244  1.629381  0.058814  0.847043      0  \n","12   -0.596641 -1.600852 -0.385575 -0.322212 -0.616050  1.775546      0  \n","13    0.955461 -1.340555  0.149616 -0.271894 -0.474894 -1.166033      0  \n","14    0.310795 -0.349746  0.742702 -0.682103 -0.886540  1.069838      0  \n","15    0.903845  0.473129  0.448787 -0.468174  0.840140  0.877578      0  \n","16    0.759456  0.259853 -0.795723  0.321710  0.295565 -0.009080      0  \n","17    0.705894  1.005478 -0.517042 -0.422063 -1.054843  1.588940      0  \n","18    1.133833 -0.563022 -1.762447  0.037931  0.841828  0.690973      0  \n","19   -0.191876  1.314476  0.398068 -0.649993  0.357148 -1.420495      0  \n","20   -0.019363 -1.186056  0.147515 -0.493010  1.834386  1.802688      0  \n","21   -1.140291 -0.158302 -0.706989 -0.433171 -0.951064  0.816507      0  \n","22   -0.782919 -0.631875 -0.561285 -0.220554  0.479227 -0.069020      0  \n","23    1.096334  1.500883  0.815548 -0.263122  0.488280  1.633047      0  \n","24    1.172698  0.264891 -0.504191  0.287952 -0.338131  0.111931      0  \n","25   -0.625357  0.627628  0.687794 -0.646691 -0.315438 -0.377767      0  \n","26   -0.807727 -1.348951  0.622144 -0.067826  0.110912 -0.684252      0  \n","27    0.199792 -1.167583 -0.471907 -0.450463 -1.015310 -1.534720      0  \n","28   -0.301795 -0.646989  0.191025 -0.632958 -0.726846  0.159430      0  \n","29    0.563197 -0.030672 -1.004046 -0.492979  0.234520 -0.499908      0  \n","...        ...       ...       ...       ...       ...       ...    ...  \n","1074 -0.019672 -0.421958  0.017463 -0.336996 -0.523032  0.649128      1  \n","1075  0.307610 -0.373257 -0.641804 -0.480973 -0.646156  0.517939      1  \n","1076 -0.618935 -0.949269 -2.041504 -0.190155 -0.949846  0.360738      1  \n","1077  0.863399 -1.024840 -1.028999 -0.520627 -0.677822  0.867400      1  \n","1078 -0.678463 -1.194452 -1.340799 -0.292448 -1.023609  0.419547      1  \n","1079 -1.207310 -1.538716 -0.294592 -0.297558 -0.668933  0.735080      1  \n","1080 -0.024605  0.362292 -0.634308 -0.573994 -0.364678  0.666092      1  \n","1081 -0.931393  0.054974 -1.925629 -0.312947 -0.605067  0.833471      1  \n","1082  0.341335 -0.196927 -1.696110 -0.220184 -0.716828  0.707937      1  \n","1083  0.004493 -0.196927  0.475063 -0.557740 -0.182345  1.132040      1  \n","1084  1.915176  1.294324  0.525133  2.907513 -0.356669 -0.316696      1  \n","1085  2.619339  1.353101  0.655774  3.172632 -0.450362 -0.418481      1  \n","1086 -0.984132  0.313592 -0.835100 -0.261326 -0.421980 -0.299732      1  \n","1087  0.641247  0.054974 -1.045454  1.260510 -0.193491 -0.295208      1  \n","1088 -0.334350 -0.811564 -0.233795  0.725040 -1.015547  0.900197      1  \n","1089  0.588547 -0.831716 -0.371391  1.094233 -1.210566  1.303943      1  \n","1090 -0.793029 -0.804846 -2.047542 -0.153357 -1.347277  1.611559      1  \n","1091 -0.995784 -1.456429 -3.346980  0.407073  0.367751 -1.266687      1  \n","1092 -2.223196 -1.416125 -2.817585  0.297458  0.412483 -1.383174      1  \n","1093  0.552861 -0.343029 -1.252800 -0.317791 -0.552590 -1.219187      1  \n","1094  0.050634 -0.287611 -2.713051 -0.309829 -0.613171 -1.202223      1  \n","1095 -0.439820 -1.538716 -0.157097 -0.442336 -1.607596 -0.693299      1  \n","1096 -0.600014 -1.631080 -1.223520 -0.179674 -1.201793 -0.625443      1  \n","1097  0.671911 -0.440430 -2.213516  0.146472 -1.362599  1.290372      1  \n","1098  1.046359 -0.428675 -2.057530  0.222187 -1.295844  1.271146      1  \n","1099 -1.028918  0.263212 -4.250083  0.253948 -1.494532  1.359359      1  \n","1100 -1.282380  0.209473 -4.325513  0.233905 -1.569354  1.389895      1  \n","1101  0.816973  0.194359 -1.034328 -0.248704 -0.141636 -0.110865      1  \n","1102  0.050254  1.107918  0.184886 -0.318348  0.075960  1.070969      1  \n","1103 -2.546996  0.830827 -0.185006  1.052421 -0.465826  0.969184      1  \n","\n","[1104 rows x 103 columns]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["((1104, 103), (438, 54))"]},"metadata":{"tags":[]},"execution_count":123}]},{"metadata":{"id":"Pzzdz5-xbeUW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"d5311014-52c3-483c-f3c1-509b42229c2f"},"cell_type":"code","source":["# prepare predictor and response arrays from data\n","x = data.values[:,2:53]\n","y = data.values[:,49:53]\n","#y = data.values[:,53]\n","print ('x:', x.shape)\n","print ('y:', y.shape)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x: (438, 51)\n","y: (438, 4)\n"],"name":"stdout"}]},{"metadata":{"id":"-peeLcs6beUc","colab_type":"text"},"cell_type":"markdown","source":["<i>I will now split the data into training (70%) and testing (30%) sets, and check that their dimensions are correct.</i>"]},{"metadata":{"id":"aGB5D6oSbeUd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"130fd812-0b2c-4975-9425-72467b803141"},"cell_type":"code","source":["# split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.7, random_state=42)\n","\n","# sanity check\n","print ('Train set: ', x_train.shape)\n","print ('Test set: ', x_test.shape)\n","print ('Train benign: {}, Train malignant: {}'.format(len(y_train[y_train==0]), len(y_train[y_train==1])))\n","print ('Test benign: {}, Test malignant: {}'.format(len(y_test[y_test==0]), len(y_test[y_test==1])))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train set:  (131, 51)\n","Test set:  (307, 51)\n","Train benign: 30, Train malignant: 4\n","Test benign: 74, Test malignant: 8\n"],"name":"stdout"}]},{"metadata":{"id":"2JDA-Cn0beUk","colab_type":"text"},"cell_type":"markdown","source":["## Model Building"]},{"metadata":{"id":"oJXAN4tXbeUl","colab_type":"text"},"cell_type":"markdown","source":["<i>I will now proceed to train 2 classifiers using random forest and support vector machine, and evaluate their performance using test accuracy, sensitivity and specificity.</i>"]},{"metadata":{"id":"4hMNEyoSbeUm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# function for computing the overall test accuracy, sensitivity and specificity of a given model\n","score = lambda model, x_test, y_test: pd.Series([model.score(x_test, y_test), \n","                                                 model.score(x_test[y_test==0], y_test[y_test==0]),\n","                                                 model.score(x_test[y_test==1], y_test[y_test==1])],\n","                                                index=['Overall test accuracy', 'Accuracy on benign (Specificity)', 'Accuracy on malignant (Sensitivity)'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rjYGGP7HbeUr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"ec52d651-4bce-4bb8-94dc-e6abfc51c61f"},"cell_type":"code","source":["# random forest\n","rf = RandomForestClassifier()\n","rf.fit(x_train, y_train)\n","rf_scores = score(rf, x_test, y_test)\n","\n","# svm\n","svm = SVC()\n","svm.fit(x_train, y_train)\n","svm_scores = score(svm, x_test, y_test)\n","\n","# present scores in a dataframe\n","score_df = pd.DataFrame({'Random Forest': rf_scores, 'SVM': svm_scores})\n","score_df"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Unknown label type: 'unknown'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-127-f93899187050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"]}]},{"metadata":{"id":"kQEUxgmvbeUx","colab_type":"text"},"cell_type":"markdown","source":["## Parameter Tuning"]},{"metadata":{"id":"8hr5RDfjbeUy","colab_type":"text"},"cell_type":"markdown","source":["<i>Now, I will try to tune the parameters of the random forest and SVM models, and see if they can perform better. For random forest, I will use 5-fold cross-validation to find the best max depth of trees. For SVM, I will use 5-fold cross-validation to find the best regularization parameter C.</i>"]},{"metadata":{"id":"lVJD3WZibeU0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# tune random forest\n","parameters = {'max_depth': range(1, 10)}\n","rf = RandomForestClassifier(class_weight='balanced', n_estimators=30)\n","rf_tuned = GridSearchCV(rf, parameters, cv=5)\n","rf_tuned.fit(x_train, y_train)\n","print ('Test accuracy for random forest model with {}: {}'.format(rf_tuned.best_params_, score(rf_tuned, x_test, y_test)[0]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NjhFHyeNbeU4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# tune svm\n","parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n","svm = SVC(class_weight='balanced', kernel='linear')\n","svm_tuned = GridSearchCV(svm, parameters, cv=5)\n","svm_tuned.fit(x_train, y_train)\n","print ('Test accuracy for SVM model with {}: {}'.format(svm_tuned.best_params_, score(svm_tuned, x_test, y_test)[0]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HjG5hC_lbeU8","colab_type":"text"},"cell_type":"markdown","source":["## Model Evaluation"]},{"metadata":{"id":"0KyCcEAJbeU9","colab_type":"text"},"cell_type":"markdown","source":["<i>Now, I will plot the Receiver Operating Characteristic (ROC) curves for the 2 models to compare their areas under the curve.</i>"]},{"metadata":{"id":"JgFugiUYbeVA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","# random forest\n","rf = RandomForestClassifier(class_weight='balanced', n_estimators=30, max_depth=6)\n","rf_probas = rf.fit(x_train, y_train).predict_proba(x_test)\n","fpr[\"RF\"], tpr[\"RF\"], _ = roc_curve(y_test, rf_probas[:, 1])\n","roc_auc[\"RF\"] = auc(fpr[\"RF\"], tpr[\"RF\"])\n","\n","# svm\n","svm = SVC(class_weight='balanced', kernel='linear', C=0.1)\n","svm_probas = svm.fit(x_train, y_train).decision_function(x_test)\n","fpr[\"SVM\"], tpr[\"SVM\"], _ = roc_curve(y_test, svm_probas)\n","roc_auc[\"SVM\"] = auc(fpr[\"SVM\"], tpr[\"SVM\"])\n","\n","# plot\n","plt.figure()\n","plt.plot(fpr[\"RF\"], tpr[\"RF\"], color='darkviolet', lw=2, label='RF (AUC = %0.2f)' % roc_auc[\"RF\"])\n","plt.plot(fpr[\"SVM\"], tpr[\"SVM\"], color='darkorange', lw=2, label='SVM (AUC = %0.2f)' % roc_auc[\"SVM\"])\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curves')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dar22N_sbeVH","colab_type":"text"},"cell_type":"markdown","source":["<i>I will now visualize the top 5 most predictive features and their relative importance in the random forest model.</i>"]},{"metadata":{"id":"4fWvYxyTbeVI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# obtain feature importance list and sort\n","importances = rf.feature_importances_\n","indices = np.argsort(importances)\n","top5_indices = indices[-5:]\n","\n","# extract gene names\n","features = data.columns\n","\n","# plot\n","plt.title('Top 5 Predictive Features')\n","plt.barh(range(len(top5_indices)), importances[top5_indices], color='blue', align='center')\n","plt.yticks(range(len(top5_indices)), features[top5_indices])\n","plt.xlabel('Relative Importance')\n","plt.show()"],"execution_count":0,"outputs":[]}]}